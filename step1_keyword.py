import csv
from datetime import datetime
import random
import time
import hashlib

def generate_keywords(client, model_name, output_file, num_keywords=2, knowledge_scope="technology", topic=None):
    # ä½¿ç”¨å¤šé‡éšæœºåŒ–ç­–ç•¥ç¡®ä¿æ¯æ¬¡ç»“æœä¸åŒ
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    microsecond_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")
    
    # ç»„åˆå¤šä¸ªéšæœºæº
    time_seed = int(time.time() * 1000000) % 100000  # å¾®ç§’çº§æ—¶é—´æˆ³
    random_seed = random.randint(1, 100000)  # æ‰©å¤§éšæœºèŒƒå›´
    hash_seed = int(hashlib.md5(microsecond_time.encode()).hexdigest()[:8], 16) % 100000
    
    # ç»„åˆç§å­ç¡®ä¿å”¯ä¸€æ€§
    combined_seed = (time_seed + random_seed + hash_seed) % 100000
    
    # æ ¹æ®çŸ¥è¯†èŒƒå›´è°ƒæ•´AIç±»åˆ«
    if "AI" in knowledge_scope or "äººå·¥æ™ºèƒ½" in knowledge_scope:
        categories = """
    1. AI Assistants (e.g. ChatGPT, Claude, Gemini)
    2. AI Note-taking Tools (e.g. Notion AI, Mem.ai)
    3. General AI Tools and Applications"""
    elif "ç§‘æŠ€" in knowledge_scope or "æŠ€æœ¯" in knowledge_scope:
        categories = """
    1. Emerging Technologies (e.g. Blockchain, IoT, AR/VR)
    2. Software Development Tools and Frameworks
    3. Tech Industry Trends and Innovations"""
    elif "å•†ä¸š" in knowledge_scope or "è¥é”€" in knowledge_scope:
        categories = """
    1. Digital Marketing and Social Media
    2. E-commerce and Online Business
    3. Business Intelligence and Analytics"""
    elif "æ•™è‚²" in knowledge_scope or "å­¦ä¹ " in knowledge_scope:
        categories = """
    1. Online Learning Platforms and EdTech
    2. Educational Technology and Tools
    3. Skills Development and Training"""
    else:
        # è‡ªå®šä¹‰èŒƒå›´ï¼Œä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„èŒƒå›´
        categories = f"""
    1. {knowledge_scope} - Core Topics and Trends
    2. {knowledge_scope} - Tools and Applications
    3. {knowledge_scope} - Industry Developments"""
    
    # æ·»åŠ æ›´å¤šéšæœºåŒ–å…ƒç´ åˆ°promptä¸­
    random_perspectives = [
        "from a startup founder's perspective",
        "from a tech investor's viewpoint", 
        "from an early adopter's angle",
        "from an industry analyst's view",
        "from a developer's standpoint",
        "from a business strategist's perspective"
    ]
    
    random_timeframes = [
        "emerging in the last 48 hours",
        "trending in the past week",
        "gaining momentum recently",
        "showing viral growth patterns",
        "experiencing sudden popularity spikes"
    ]
    
    selected_perspective = random.choice(random_perspectives)
    selected_timeframe = random.choice(random_timeframes)
    
    # ä¿®æ”¹promptï¼Œè¦æ±‚ç”Ÿæˆå¯åˆ†å‰²çš„å…³é”®è¯
    # åœ¨promptä¸­æ·»åŠ ä¸»é¢˜ç›¸å…³å†…å®¹
    topic_context = f"\nSpecific topic focus: {topic}" if topic else ""
    
    prompt = f"""
    As a trend analyst specializing in {knowledge_scope}, identify the {num_keywords} most trending and popular keywords from X (Twitter) & reddit & medium discussions at {current_time}.{topic_context}
    
    Analyze {selected_perspective} and focus on topics {selected_timeframe}.
    
    Focus on these categories related to {knowledge_scope}:
    {categories}
    
    Requirements:
    - Return EXACTLY {num_keywords} keywords from different categories above
    - Keywords must be currently trending and relevant to {knowledge_scope}
    {f"- All keywords should be related to or inspired by: {topic}" if topic else ""}
    - Consider topics with high search volume and viral discussions (unique seed: {combined_seed})
    - Focus on emerging topics and developments in {knowledge_scope}
    - Look for sudden spikes in discussion and engagement
    - Consider global trends across different regions
    - Prioritize fresh and currently active discussions
    - Ensure completely different results each time (randomization key: {hash_seed})
    - Avoid previously common keywords, seek novel trending terms
    - IMPORTANT: Output keywords as comma-separated values for better processing
    
    Format: Output each keyword set as comma-separated values on one line.
    Example: artificial intelligence, machine learning, technology
    
    Just output the {num_keywords} keyword sets directly, one per line, without any additional text or explanations.
    Do not include any headers, bullet points, or section markers.
    """
    
    response = client.chat.completions.create(
        model=model_name,
        messages=[{"role": "user", "content": prompt}],
        temperature=1.0,  # ä¿æŒæœ€å¤§éšæœºæ€§
        seed=combined_seed  # ä½¿ç”¨ç»„åˆç§å­
    )
    
    # å¤„ç†å…³é”®è¯ï¼Œç¡®ä¿æ¯ä¸ªå…³é”®è¯å•ç‹¬ä¿å­˜
    raw_keywords = [k.strip('- ') for k in response.choices[0].message.content.strip().split('\n') 
                  if k.strip() and not k.startswith('#') and not k.startswith('##')][:num_keywords]
    
    processed_keywords = []
    for keyword_line in raw_keywords:
        if keyword_line:
            # å¦‚æœåŒ…å«é€—å·ï¼ŒæŒ‰é€—å·åˆ†å‰²æˆå¤šä¸ªå…³é”®è¯
            if ',' in keyword_line:
                # æŒ‰é€—å·åˆ†å‰²å¹¶æ¸…ç†æ¯ä¸ªå…³é”®è¯
                split_keywords = [k.strip().lower() for k in keyword_line.split(',') if k.strip()]
                processed_keywords.extend(split_keywords)
            else:
                # å•ä¸ªå…³é”®è¯ç›´æ¥æ·»åŠ 
                processed_keywords.append(keyword_line.strip().lower())
    
    # ä¿å­˜åˆ°CSVæ–‡ä»¶
    import csv
    with open(output_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['Keyword'])
        for keyword in processed_keywords:
            if keyword:  # åªå†™å…¥éç©ºå…³é”®è¯
                writer.writerow([keyword])
    
    print(f"âœ… å·²ä¿å­˜{len(processed_keywords)}ä¸ªå…³é”®è¯åˆ°{output_file} (ç§å­: {combined_seed})")
    print(f"ğŸ“ ç”Ÿæˆçš„å…³é”®è¯: {processed_keywords}")