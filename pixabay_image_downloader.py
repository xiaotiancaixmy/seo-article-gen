import requests
import os
from PIL import Image
import io
import time
from urllib.parse import urlparse

class PixabayImageDownloader:
    def __init__(self, api_key):
        self.api_key = api_key
        self.base_url = "https://pixabay.com/api/"
        self.download_folder = "pixabay_ai_images"
        
        # åˆ›å»ºä¸‹è½½æ–‡ä»¶å¤¹
        if not os.path.exists(self.download_folder):
            os.makedirs(self.download_folder)
    
    def search_images(self, query, per_page=100, image_type="photo", category="science", orientation="horizontal"):
        """
        æœç´¢Pixabayå›¾ç‰‡
        """
        params = {
            'key': self.api_key,
            'q': query,
            'image_type': image_type,
            'category': category,
            'orientation': orientation,  # æ·»åŠ æ¨ªå‘ï¼ˆlandscapeï¼‰å‚æ•°
            'per_page': per_page,
            'safesearch': 'true',
            'order': 'popular',
            'min_width': 1920,  # ç¡®ä¿å›¾ç‰‡è´¨é‡ï¼Œæœ€å°å®½åº¦
            'min_height': 1080   # ç¡®ä¿å›¾ç‰‡è´¨é‡ï¼Œæœ€å°é«˜åº¦
        }
        
        try:
            response = requests.get(self.base_url, params=params)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"æœç´¢å›¾ç‰‡æ—¶å‡ºé”™: {e}")
            return None
    
    def download_and_convert_image(self, image_url, filename):
        """
        ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºwebpæ ¼å¼
        """
        try:
            # ä¸‹è½½å›¾ç‰‡
            response = requests.get(image_url, timeout=30)
            response.raise_for_status()
            
            # ä½¿ç”¨PILæ‰“å¼€å›¾ç‰‡
            image = Image.open(io.BytesIO(response.content))
            
            # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦ä¸ºlandscapeæ ¼å¼ï¼ˆå®½åº¦å¤§äºé«˜åº¦ï¼‰
            width, height = image.size
            if width <= height:
                print(f"è·³è¿‡élandscapeæ ¼å¼å›¾ç‰‡: {filename} ({width}x{height})")
                return False
            
            # è½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆwebpéœ€è¦ï¼‰
            if image.mode in ('RGBA', 'LA', 'P'):
                image = image.convert('RGB')
            
            # ä¿å­˜ä¸ºwebpæ ¼å¼
            webp_filename = f"{filename}.webp"
            webp_path = os.path.join(self.download_folder, webp_filename)
            
            # ä¿å­˜æ—¶è®¾ç½®è´¨é‡å‚æ•°
            image.save(webp_path, 'WEBP', quality=85, optimize=True)
            
            print(f"æˆåŠŸä¸‹è½½å¹¶è½¬æ¢: {webp_filename} ({width}x{height})")
            return True
            
        except Exception as e:
            print(f"ä¸‹è½½å›¾ç‰‡ {filename} æ—¶å‡ºé”™: {e}")
            return False
    
    def download_ai_images(self, max_images=50):
        """
        ä¸‹è½½AIç›¸å…³çš„ç§‘æŠ€æ„Ÿå›¾ç‰‡ï¼ˆlandscapeæ ¼å¼ï¼Œä¸åŒ…å«æœºå™¨äººï¼‰
        """
        # ç§‘æŠ€æ„Ÿç›¸å…³çš„æœç´¢å…³é”®è¯ï¼ˆæ’é™¤æœºå™¨äººç›¸å…³ï¼‰
        tech_keywords = [
            "hardware technology",
            "keyboard",
            "technology",
            "fiber cable",
            "workspace",
            "computer science technology",
            "digital transformation",
            "tech innovation",
            "futuristic technology",
            "digital network",
            "cyber technology",
            "AI abstract concept",
            "technology background",
            "digital innovation"
        ]
        
        downloaded_count = 0
        
        for keyword in tech_keywords:
            if downloaded_count >= max_images:
                break
                
            print(f"\næ­£åœ¨æœç´¢å…³é”®è¯: {keyword}")
            
            # è®¡ç®—è¿™æ¬¡æœç´¢éœ€è¦çš„å›¾ç‰‡æ•°é‡
            remaining_images = max_images - downloaded_count
            per_page = min(remaining_images, 20)  # Pixabay APIé™åˆ¶æ¯æ¬¡æœ€å¤š20å¼ 
            
            # æœç´¢å›¾ç‰‡ï¼ˆæŒ‡å®šæ¨ªå‘orientationï¼‰
            search_result = self.search_images(keyword, per_page=per_page, orientation="horizontal")
            
            if not search_result or 'hits' not in search_result:
                print(f"æœç´¢ {keyword} å¤±è´¥")
                continue
            
            images = search_result['hits']
            print(f"æ‰¾åˆ° {len(images)} å¼ å›¾ç‰‡")
            
            # è¿‡æ»¤æ‰åŒ…å«æœºå™¨äººç›¸å…³æ ‡ç­¾çš„å›¾ç‰‡
            filtered_images = []
            robot_keywords = ['robot', 'android', 'humanoid', 'cyborg', 'droid']
            
            for image_data in images:
                tags = image_data.get('tags', '').lower()
                if not any(robot_word in tags for robot_word in robot_keywords):
                    filtered_images.append(image_data)
            
            print(f"è¿‡æ»¤åå‰©ä½™ {len(filtered_images)} å¼ éæœºå™¨äººç›¸å…³å›¾ç‰‡")
            
            # ä¸‹è½½å›¾ç‰‡
            for i, image_data in enumerate(filtered_images):
                if downloaded_count >= max_images:
                    break
                
                # è·å–å›¾ç‰‡URLï¼ˆä¼˜å…ˆé€‰æ‹©é«˜è´¨é‡ï¼‰
                image_url = image_data.get('largeImageURL') or image_data.get('webformatURL')
                
                if not image_url:
                    continue
                
                # ç”Ÿæˆæ–‡ä»¶å
                filename = f"tech_landscape_{downloaded_count + 1:03d}_{keyword.replace(' ', '_')}_{image_data['id']}"
                
                # ä¸‹è½½å¹¶è½¬æ¢å›¾ç‰‡
                if self.download_and_convert_image(image_url, filename):
                    downloaded_count += 1
                    print(f"è¿›åº¦: {downloaded_count}/{max_images}")
                
                # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(0.5)
        
        print(f"\nä¸‹è½½å®Œæˆï¼æ€»å…±ä¸‹è½½äº† {downloaded_count} å¼ ç§‘æŠ€æ„Ÿlandscapeå›¾ç‰‡")
        print(f"å›¾ç‰‡ä¿å­˜åœ¨: {os.path.abspath(self.download_folder)}")
        
        return downloaded_count

def main():
    # Pixabay APIå¯†é’¥
    API_KEY = "50940935-6df1a344f2b603680d7a7f9b6"
    
    if API_KEY == "YOUR_PIXABAY_API_KEY":
        print("é”™è¯¯: è¯·å…ˆè®¾ç½®æ‚¨çš„Pixabay APIå¯†é’¥")
        print("1. è®¿é—® https://pixabay.com/api/docs/")
        print("2. æ³¨å†Œè´¦æˆ·å¹¶è·å–APIå¯†é’¥")
        print("3. å°†API_KEYå˜é‡æ›¿æ¢ä¸ºæ‚¨çš„å¯†é’¥")
        return
    
    # åˆ›å»ºä¸‹è½½å™¨å®ä¾‹
    downloader = PixabayImageDownloader(API_KEY)
    
    print("å¼€å§‹ä¸‹è½½ç§‘æŠ€æ„Ÿlandscapeå›¾ç‰‡...")
    print("ç›®æ ‡: 50å¼ å›¾ç‰‡ï¼Œwebpæ ¼å¼ï¼Œlandscapeæ–¹å‘ï¼Œæ— æœºå™¨äººå†…å®¹")
    print("-" * 60)
    
    # å¼€å§‹ä¸‹è½½
    downloaded_count = downloader.download_ai_images(max_images=50)
    
    if downloaded_count > 0:
        print(f"\nâœ… æˆåŠŸä¸‹è½½ {downloaded_count} å¼ ç§‘æŠ€æ„Ÿlandscapeå›¾ç‰‡")
        print(f"ğŸ“ ä¿å­˜ä½ç½®: {os.path.abspath(downloader.download_folder)}")
        print("ğŸ–¼ï¸  æ ¼å¼: WebP")
        print("ğŸ“ æ–¹å‘: Landscape (æ¨ªå‘)")
        print("ğŸš« å·²æ’é™¤: æœºå™¨äººç›¸å…³å†…å®¹")
    else:
        print("âŒ æ²¡æœ‰æˆåŠŸä¸‹è½½ä»»ä½•å›¾ç‰‡")

if __name__ == "__main__":
    main()